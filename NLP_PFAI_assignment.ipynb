{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P.S. to run again the code, please use the .csv files existed in this .zip.\n",
    "The data columns had to be named. so, a slight change in .txt files load data into pandas dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_10136/653030402.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  test_dataset = test_dataset[pd.notnull(dataset['Example'])]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trade</td>\n",
       "      <td>asian exporters fear damage from u s japan rif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grain</td>\n",
       "      <td>china daily says vermin eat pct grain stocks a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ship</td>\n",
       "      <td>australian foreign ship ban ends but nsw ports...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acq</td>\n",
       "      <td>sumitomo bank aims at quick recovery from merg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>earn</td>\n",
       "      <td>amatil proposes two for five bonus share issue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2184</th>\n",
       "      <td>money-fx</td>\n",
       "      <td>balladur insists on maintenance of louvre acco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2185</th>\n",
       "      <td>trade</td>\n",
       "      <td>philippine trade gap widens in january august ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>crude</td>\n",
       "      <td>iran soviet union to swap crude refined produc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>acq</td>\n",
       "      <td>n z s chase corp makes offer for entregrowth c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>ship</td>\n",
       "      <td>japan india conference cuts gulf war risk char...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2189 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Class                                            Example\n",
       "0        trade  asian exporters fear damage from u s japan rif...\n",
       "1        grain  china daily says vermin eat pct grain stocks a...\n",
       "2         ship  australian foreign ship ban ends but nsw ports...\n",
       "3          acq  sumitomo bank aims at quick recovery from merg...\n",
       "4         earn  amatil proposes two for five bonus share issue...\n",
       "...        ...                                                ...\n",
       "2184  money-fx  balladur insists on maintenance of louvre acco...\n",
       "2185     trade  philippine trade gap widens in january august ...\n",
       "2186     crude  iran soviet union to swap crude refined produc...\n",
       "2187       acq  n z s chase corp makes offer for entregrowth c...\n",
       "2188      ship  japan india conference cuts gulf war risk char...\n",
       "\n",
       "[2189 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('r8-train-all-terms.txt', delimiter = '\\t', quoting = 3)\n",
    "test_dataset = pd.read_csv('r8-test-all-terms.txt', delimiter = '\\t', quoting = 3)\n",
    "dataset = dataset[pd.notnull(dataset['Example'])]\n",
    "test_dataset = test_dataset[pd.notnull(dataset['Example'])]\n",
    "\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_by_space_re = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "bad_symbols_re = re.compile('[^0-9a-z #+_]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range(0,5485):\n",
    "    example = re.sub ('[^a-zA-Z]', ' ', dataset['Example'][i])\n",
    "    example = example.lower()\n",
    "    example = example.split()\n",
    "    ps = PorterStemmer()\n",
    "    all_stopwords = stopwords.words('english')\n",
    "    example = [ps.stem(word) for word in example if not word in set(all_stopwords)]\n",
    "    example = ' '.join(example)\n",
    "    corpus.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "test_corpus= []\n",
    "for i in range(0, 2189):\n",
    "    example = re.sub('[^a-zA-Z]', ' ', test_dataset['Example'][i])\n",
    "    example = example.lower()\n",
    "    example = example.split()\n",
    "    ps = PorterStemmer()\n",
    "    all_stopwords = stopwords.words('english')\n",
    "    # all_stopwords.remove('not')\n",
    "    example = [ps.stem(word) for word in example if not word in set(all_stopwords)]\n",
    "    example = ' '.join(example)\n",
    "    test_corpus.append(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [str(item) for item in corpus]\n",
    "\n",
    "X_train = corpus\n",
    "y_train = dataset['Class']\n",
    "\n",
    "X_test = test_corpus\n",
    "y_test = test_dataset['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 662    0   34    0    0    0    0    0]\n",
      " [  32   69   20    0    0    0    0    0]\n",
      " [  10    0 1073    0    0    0    0    0]\n",
      " [   5    0    5    0    0    0    0    0]\n",
      " [  32    0   37    0   10    2    0    0]\n",
      " [  59    0   15    0    0   13    0    0]\n",
      " [  28    3    3    0    0    0    0    2]\n",
      " [  20    0   19    0    0    0    0   36]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8510735495660119"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=5485)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "247ab06e135bb35fa78c5eff31b2a9a0050dcb5fb773c2631d2a29ac689eeccb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
